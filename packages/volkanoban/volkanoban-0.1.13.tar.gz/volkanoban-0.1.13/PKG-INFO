Metadata-Version: 2.1
Name: volkanoban
Version: 0.1.13
Summary: A library for data analysis and supervised learning modeling using various powerful machine learning techniques.
Author: Dr. Volkan OBAN
Author-email: volkanobn@gmail.com
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENCE.txt
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: scikit-learn
Requires-Dist: matplotlib
Requires-Dist: seaborn
Requires-Dist: lime
Requires-Dist: xgboost
Requires-Dist: lightgbm
Requires-Dist: catboost
Requires-Dist: plotly
Requires-Dist: tabulate

# Volkanoban Library

Volkanoban is a Python library designed for data analysis and modeling using various machine learning techniques. The primary focus of this library is to provide an effective stacking classifier that combines multiple machine learning models to improve prediction accuracy and robustness.

## Purpose of the Stacking Classifier

Stacking classifiers are ensemble learning methods that combine different base models to improve predictive performance. By leveraging the strengths of multiple algorithms, stacking can yield better results than any single model. The `volkanoban` library integrates various classifiers to provide a more comprehensive solution for classification problems.

### Features of the Stacking Classifier

The stacking classifier in the Volkanoban library includes the following models as base learners:

- **Random Forest Classifier**: An ensemble method that uses multiple decision trees to improve classification accuracy and control overfitting.
- **XGBoost**: A powerful gradient boosting algorithm that optimizes performance and speed, widely used in machine learning competitions.
- **LightGBM**: A gradient boosting framework that uses tree-based learning algorithms, designed for high performance and efficiency.
- **CatBoost**: A gradient boosting algorithm that handles categorical features automatically and provides high performance with less tuning.
- **Extra Trees Classifier**: An ensemble method that builds multiple trees using random splits and averages their predictions.
- **Multi-layer Perceptron (MLP)**: A type of neural network that is capable of learning complex patterns in the data.
- **Bagging Classifier**: A meta-estimator that fits base classifiers on random subsets of the data and averages their predictions.

### Installation

You can install the library using pip:

```bash
pip install volkanoban


### Usage Example

import pandas as pd

from sklearn.datasets import load_breast_cancer

from volkanoban import volkanoban_classifier, lime_analysis, plot_feature_importance

# Load the Breast Cancer dataset


data = load_breast_cancer()

X = pd.DataFrame(data.data, columns=data.feature_names)  # Create a DataFrame with feature names

y = pd.Series(data.target)  # Create a Series with target labels


# Handle missing values (if any)


X.fillna(X.mean(), inplace=True)


# Split the dataset into training and testing sets


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Train the model using the volkanoban_classifier


stacking_model, X_train, X_test, y_train, y_test, y_pred = volkanoban_classifier(X, y)



# Define feature names from the original dataset

feature_names = X.columns.tolist()  # Assuming X is your DataFrame with features

# Perform LIME analysis on the first instance in the test set

lime_analysis(stacking_model, X_train, X_test, y_test, feature_names)




# Show feature importance from the stacking model


plot_feature_importance(stacking_model, X.columns)
