from _typeshed import Incomplete
from amsdal_data.connections.errors import AmsdalConnectionError as AmsdalConnectionError
from amsdal_data.connections.historical_base import HistoricalConnectionBase as HistoricalConnectionBase
from amsdal_data.connections.utils import sort_items as sort_items
from amsdal_data.table_schemas.base import TableSchemaServiceBase as TableSchemaServiceBase
from amsdal_data.table_schemas.constants import PRIMARY_PARTITION_KEY as PRIMARY_PARTITION_KEY, SECONDARY_PARTITION_KEY as SECONDARY_PARTITION_KEY
from amsdal_data.table_schemas.data_models.iceberg_table_column import ComplexType as ComplexType, IcebergDataTypes as IcebergDataTypes, IcebergTableColumn as IcebergTableColumn, ListType as ListType, MapType as MapType, StructType as StructType, python_to_iceberg_types as python_to_iceberg_types
from amsdal_utils.models.data_models.address import Address
from amsdal_utils.models.data_models.table_schema import TableSchema as TableSchema
from amsdal_utils.models.enums import Versions
from amsdal_utils.query.data_models.filter import Filter as Filter
from amsdal_utils.query.data_models.order_by import OrderBy as OrderBy
from amsdal_utils.query.data_models.paginator import CursorPaginator, NumberPaginator
from amsdal_utils.query.data_models.query_specifier import QuerySpecifier as QuerySpecifier
from amsdal_utils.query.enums import Lookup
from amsdal_utils.query.utils import Q
from collections.abc import Callable as Callable
from pydantic import BaseModel
from pyspark.sql import DataFrame as DataFrame, Row, SparkSession
from typing import Any, ClassVar

SUPPORTED_NESTED_FIELDS: Incomplete
logger: Incomplete
DEFAULT_PACKAGES: Incomplete
DEFAULT_COMMON_CONNECTION_CONFIGS: Incomplete
DEFAULT_MASTER_CONNECTION_CONFIGS: Incomplete
SPARK_ENVS: list[tuple[str, str]]

def random_string(length: int = 10) -> str:
    """
    Generates a random string of lowercase letters.

    Args:
        length (int, optional): The length of the random string. Defaults to 10.

    Returns:
        str: A random string of the specified length.
    """

class SqlOperatorTemplate(BaseModel):
    """
    Represents a SQL operator template for building SQL statements and values.

    Attributes:
        build_statement (ClassVar\\[Callable\\[\\[Any, str, str, Any\\], str\\]\\]): A callable to build the SQL statement.
        build_value (ClassVar\\[Callable\\[\\[Any, Any\\], Any\\]\\]): A callable to build the SQL value.
        template (str | Callable\\[\\[Any\\], str\\]): The template for the SQL statement.
        value_template (str | None): The template for the SQL value.
        value_modifier (Callable\\[\\[Any\\], Any\\] | None): A function to modify the SQL value.
    """
    build_statement: ClassVar[Callable[[Any, str, str, Any], str]]
    build_value: ClassVar[Callable[[Any, Any], Any]]
    template: str | Callable[[Any], str]
    value_template: str | None
    value_modifier: Callable[[Any], Any] | None
    def build_statement(self, field_name: str, filter_key: str, value: Any, **kwargs: Any) -> str: ...
    def build_value(self, value: Any) -> Any: ...

sql_operator_map: dict[Lookup, SqlOperatorTemplate]

def _cut_nested_struct(data_type: str, start_index: int) -> list[str]: ...
def _process_struct_description_type(data_type: str) -> dict[str, IcebergDataTypes | ComplexType]: ...
def process_table_description_type(data_type: str) -> IcebergDataTypes | ComplexType: ...

class IcebergHistoricalConnection(HistoricalConnectionBase):
    def bulk_put(self, data: list[tuple[Address, dict[str, Any]]]) -> None: ...
    @property
    def queries(self) -> list[str]: ...
    _connection: Incomplete
    catalog_name: Incomplete
    namespace_name: Incomplete
    _branches_lineage: Incomplete
    _branches_changes: Incomplete
    _branches_revert: Incomplete
    _filter_counter: int
    _is_remote: bool
    _configs: Incomplete
    def __init__(self, catalog_name: str = 'amsdal', namespace: str = 'amsdal') -> None: ...
    def build_columns_from_schema(self, table_schema: TableSchema) -> list[IcebergTableColumn]: ...
    @classmethod
    def _to_sql_type(cls, type_: Any) -> IcebergDataTypes | ComplexType: ...
    @property
    def table_schema_manager(self) -> TableSchemaServiceBase: ...
    @property
    def connection(self) -> SparkSession: ...
    def _prepopulate_values_from_envs(self, configs: dict[str, str]) -> dict[str, str]: ...
    @property
    def is_connected(self) -> bool: ...
    @property
    def is_alive(self) -> bool: ...
    def connect(self, app_name: str = 'amsdal', catalog_name: str = 'amsdal', namespace_name: str = 'amsdal', spark_master: str | None = None, spark_remote: str | None = None, log_level: str = 'ERROR', configs: dict[str, str] | None = None, **kwargs: Any) -> None:
        """
        Connects to the PySpark cluster. Raises an AmsdalConnectionError if the connection is already established.
        :param app_name: the name of the application
        :type app_name: str
        :param catalog_name: the name of the Iceberg catalog
        :type catalog_name: str
        :param namespace_name: the name of the Iceberg namespace
        :type namespace_name: str
        :param spark_master: the Spark master URL
        :type spark_master: str | None
        :param spark_remote: the Spark Connect URL
        :type spark_remote: str | None
        :param log_level: the log level to set for a Standalone Spark cluster
        :type log_level: str
        :param configs: the connection configs parameters to pass to the SparkSession
        :type configs: dict[str, str] | None
        :param kwargs: the connection parameters
        :type kwargs: Any

        :return: None
        """
    def _apply_remote_configs(self) -> None: ...
    def disconnect(self) -> None: ...
    def _current_branch_name(self) -> str | None: ...
    def _set_branch(self, branch: str) -> None: ...
    def begin(self) -> None: ...
    def commit(self) -> None: ...
    def revert(self) -> None: ...
    def on_transaction_complete(self) -> None: ...
    def rollback(self) -> None: ...
    def _preprocess_data(self, value: Any, field_type: str | ComplexType) -> tuple[str, Any]: ...
    def put(self, address: Address, data: dict[str, Any]) -> None: ...
    def get_table_description(self, table_name: str) -> list[IcebergTableColumn]: ...
    def _get_latest_snapshot_id(self, table_name: str) -> int | None: ...
    def execute(self, stm: str, values: dict[str, Any] | None = None) -> DataFrame: ...
    def get_full_table_name(self, address: Address) -> str: ...
    def _table_name_with_catalog(self, table_name: str) -> str: ...
    def _get_metadata_fields(self, join_table: str = 'm', fields_rename_prefix: str = '_metadata__', *, needs_rename: bool = True, with_references: bool = False) -> str: ...
    def _concat_references(self, field_prefix: str, rename_field: str) -> str: ...
    def _metadata_next_version(self, metadata_table_name: str) -> str: ...
    def _select_statement(self, select_only: str, table_name: str, main_table_name: str, metadata_join_table: str, conditions: Q | None = None, *, is_internal_table: bool) -> tuple[str, dict[str, Any]]: ...
    def _build_select_statement(self, address: Address, query_specifier: QuerySpecifier | None = None, conditions: Q | None = None, pagination: NumberPaginator | CursorPaginator | None = None, order_by: list[OrderBy] | None = None) -> tuple[str, dict[str, Any]]: ...
    def _build_count_statement(self, address: Address, conditions: Q | None = None) -> tuple[str, dict[str, Any]]: ...
    def _process_row_value(self, value: Any) -> Any: ...
    def _process_row_into_result(self, row: Row, table_description: dict[str, IcebergTableColumn]) -> dict[str, Any]: ...
    def _split_conditions_by_class_version(self, address: Address, conditions: Q | None) -> dict[str, Q | None]: ...
    def query(self, address: Address, query_specifier: QuerySpecifier | None = None, conditions: Q | None = None, pagination: NumberPaginator | CursorPaginator | None = None, order_by: list[OrderBy] | None = None, select_related: dict[tuple[str, Address, str], Any] | None = None) -> list[dict[str, Any]]: ...
    def _query(self, address: Address, class_version: str | Versions, query_specifier: QuerySpecifier | None = None, query: Q | None = None, pagination: NumberPaginator | CursorPaginator | None = None, order_by: list[OrderBy] | None = None) -> list[dict[str, Any]]: ...
    @staticmethod
    def _paginate_items(items: list[dict[str, Any]], pagination: NumberPaginator | CursorPaginator | None) -> list[dict[str, Any]]: ...
    def count(self, address: Address, conditions: Q | None = None) -> int: ...
    def _count(self, address: Address, class_version: str | Versions, conditions: Q | None = None) -> int: ...
    def _get_conditions_statement(self, conditions: Q, *, is_grouped: bool = False) -> tuple[str, dict[str, Any]]: ...
    def _get_filter_statement(self, filter_item: Filter) -> tuple[str, dict[Any, Any]] | tuple[None, None]: ...
    @staticmethod
    def _to_sql_value(value: Any) -> Any: ...
    def prepare_connection(self) -> None: ...
