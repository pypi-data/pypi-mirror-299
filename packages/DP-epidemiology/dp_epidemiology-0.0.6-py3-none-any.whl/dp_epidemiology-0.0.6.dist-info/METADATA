Metadata-Version: 2.3
Name: DP_epidemiology
Version: 0.0.6
Summary: A package for differential private release of fianancial data in context of epidemiology
Project-URL: Homepage, https://pets-for-public-health-challenge.readthedocs.io/en/latest/
Project-URL: repository, https://github.com/KnowledgeEdgeAI/PETs_for_Public_Health_Challenge/tree/main
Author-email: Shubham Kumar <sk834rk@gmail.com>, Milan Anand Raj <milananandraj1502@gmail.com>, Divya Gupta <divygupt2002@gmail.com>
License-File: LICENSE
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.10
Requires-Dist: alabaster==0.7.16
Requires-Dist: antlr4-python3-runtime==4.13.2
Requires-Dist: asttokens==2.4.1
Requires-Dist: attrs==24.2.0
Requires-Dist: babel==2.16.0
Requires-Dist: backports-tarfile==1.2.0
Requires-Dist: blinker==1.8.2
Requires-Dist: build==1.2.2
Requires-Dist: certifi==2024.8.30
Requires-Dist: charset-normalizer==3.3.2
Requires-Dist: click==8.1.7
Requires-Dist: colorama==0.4.6
Requires-Dist: comm==0.2.2
Requires-Dist: dash-core-components==2.0.0
Requires-Dist: dash-html-components==2.0.0
Requires-Dist: dash-table==5.0.0
Requires-Dist: dash==2.18.1
Requires-Dist: debugpy==1.8.1
Requires-Dist: decorator==5.1.1
Requires-Dist: docutils==0.20.1
Requires-Dist: exceptiongroup==1.2.1
Requires-Dist: executing==2.0.1
Requires-Dist: fastjsonschema==2.20.0
Requires-Dist: flask==3.0.3
Requires-Dist: idna==3.10
Requires-Dist: imagesize==1.4.1
Requires-Dist: importlib-metadata==8.5.0
Requires-Dist: itsdangerous==2.2.0
Requires-Dist: jaraco-classes==3.4.0
Requires-Dist: jaraco-context==6.0.1
Requires-Dist: jaraco-functools==4.0.2
Requires-Dist: jedi==0.19.1
Requires-Dist: jinja2==3.1.4
Requires-Dist: jsonschema-specifications==2023.12.1
Requires-Dist: jsonschema==4.23.0
Requires-Dist: jupyter-client==8.6.2
Requires-Dist: jupyter-core==5.7.2
Requires-Dist: keyring==25.4.1
Requires-Dist: markdown-it-py==3.0.0
Requires-Dist: markupsafe==2.1.5
Requires-Dist: matplotlib-inline==0.1.7
Requires-Dist: mdurl==0.1.2
Requires-Dist: more-itertools==10.5.0
Requires-Dist: msrest==0.7.1
Requires-Dist: nbformat==5.10.4
Requires-Dist: nest-asyncio==1.6.0
Requires-Dist: nh3==0.2.18
Requires-Dist: numpy>=1.26.4
Requires-Dist: opendp==0.11.1
Requires-Dist: packaging==24.1
Requires-Dist: pandas>=2.1.4
Requires-Dist: parso==0.8.4
Requires-Dist: pkginfo==1.10.0
Requires-Dist: platformdirs==4.2.2
Requires-Dist: plotly==5.24.1
Requires-Dist: psutil==6.0.0
Requires-Dist: pure-eval==0.2.2
Requires-Dist: pygments==2.18.0
Requires-Dist: pyproject-hooks==1.1.0
Requires-Dist: python-dateutil==2.9.0.post0
Requires-Dist: pytz==2024.2
Requires-Dist: referencing==0.35.1
Requires-Dist: requests-toolbelt==1.0.0
Requires-Dist: requests==2.32.3
Requires-Dist: retrying==1.3.4
Requires-Dist: rfc3986==2.0.0
Requires-Dist: rich==13.8.1
Requires-Dist: rpds-py==0.20.0
Requires-Dist: six==1.16.0
Requires-Dist: snowballstemmer==2.2.0
Requires-Dist: sphinx-rtd-theme==2.0.0
Requires-Dist: sphinx==7.4.7
Requires-Dist: sphinxcontrib-applehelp==2.0.0
Requires-Dist: sphinxcontrib-devhelp==2.0.0
Requires-Dist: sphinxcontrib-htmlhelp==2.1.0
Requires-Dist: sphinxcontrib-jquery==4.1
Requires-Dist: sphinxcontrib-jsmath==1.0.1
Requires-Dist: sphinxcontrib-qthelp==2.0.0
Requires-Dist: sphinxcontrib-serializinghtml==2.0.0
Requires-Dist: stack-data==0.6.3
Requires-Dist: tenacity==9.0.0
Requires-Dist: tomli==2.0.1
Requires-Dist: traitlets==5.14.3
Requires-Dist: twine==5.1.1
Requires-Dist: typing-extensions==4.12.2
Requires-Dist: tzdata==2024.2
Requires-Dist: urllib3==2.2.3
Requires-Dist: wcwidth==0.2.13
Requires-Dist: werkzeug==3.0.4
Requires-Dist: zipp==3.20.2
Description-Content-Type: text/x-rst

Hotspot Detection, Mobility, Pandemic Stages and Contact Metric using Differential Privacy
===========================================================================================

.. image:: https://readthedocs.org/projects/pets-for-public-health-challenge/badge/?version=latest
    :target: https://pets-for-public-health-challenge.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. This README.rst should render properly both on GitHub and in Sphinx.

Hotspot Detection
-----------------

Description

Areas with high physical economic activities can be identified as a pandemic hotspot. This analysis tracks pandemic hotspots by monitoring differential private release of financial transactions in a city and identifying areas with high transaction activity.

Assumptions

* Transaction type : Only ``OFFLINE`` transactions contribute to physical hotspots.  
* Transaction metric : Number of transactions is more relevant than the total value of transactions.  
* Maximum transaction cap : Maximum number of transactions (``nb_transaction``) is assumed to be ``454``. Setting a bound of ``(0,600)``.  
* Public data : Number of postal codes in a city is assumed to be public information.  

Algorithm

#. Add City Column: A new ``city`` column is added based on the postal codes (``make_preprocess_location``).
#. Filter OFFLINE Transactions: Only "OFFLINE" transactions are considered (``make_filter``).
#. Filter City Postal Codes: Filter for the postal codes of the selected city (``make_filter``).
#. Filter by Time Frame : Filter data for the selected time frame (``make_truncate_time``).
#. Transaction Summing & Noise Addition: Sum the number of transactions by postal code, and add Gaussian noise (``make_private_sum_by``).
#. Visualization: Differentially private data is plotted on a colored map for hotspot visualization.

Sensitivity and Epsilon Analysis

* Sensitivity : In a single time stamp, ``1`` merchant can come only once in a particular zip code but can appear in upto ``3`` zip codes. So, if we wanted to release measures about a single zip code sensitivity would be ``1``  but since we want to release data for all zip codes, the sensitivity used for each zip code is ``3``.
* Scaling with Time: For multiple time stamps, sensitivity is ``3 * no_of_time_stamps``.
* Epsilon Budget: The epsilon spent for each query is ``∈``.
* Scale Calculation: ``Scale = (sqrt(3) * no_of_time_stamps) / ∈``.


Mobility Detection (Airline Merch Category)
-------------------------------------------

Description

This analysis tracks mobility by monitoring differential private time series release of financial transactions in the "Airlines" category, which reflects the transportation sector.

Assumptions

* Transaction metric : Number of transactions is more relevant than the total value.
* Online and Offline transactions : Both contribute to mobility inference.
* Maximum transaction cap: Maximum number of transactions (``nb_transaction``) is assumed to be ``454``. Setting a bound of ``(0,600)``.

Algorithm

#. Add City Column: A new ``city`` column is added based on postal codes (``make_preprocess_location``).
#. Filter for City: Data for the selected city is filtered (``make_filter``).
#. Filter for Airline Category: Only transactions in the ``Airline`` category are considered (``make_filter``).
#. Filter by Time Frame: Data is filtered for the selected time frame (``make_truncate_time``).
#. Transaction Summing & Noise Addition: Sum the number of transactions by postal code for each timestep and add Gaussian noise (``make_private_sum_by``).

Sensitivity and Epsilon Analysis

* Sensitivity per Merchant: Sensitivity is 3 for each merchant in the ``Airline`` category.
* Scaling with Time: For multiple timesteps, sensitivity is ``3 * no_of_time_steps``.
* Epsilon Budget: The epsilon spent per timestep is ∈ .
* Scale Calculation: ``Scale = (3 * no_of_time_steps) / ∈``.

Validation

* External Data Comparison: Compare mobility results with publicly available COVID-19 mobility reports, e.g.,  `Google COVID-19 Mobility Report for Bogotá <https://www.gstatic.com/covid19/mobility/2022-10-15_CO_Bogota_Mobility_Report_en.pdf>`_


Pandemic Stages Detection
-------------------------

Description

Analyzes transaction behavior to identify pandemic stages by comparing transactions in essential vs luxurious goods categories.

Assumptions

*  Essential Goods: Includes ``Utilities (Electric, Gas, Water), Drug Stores, Grocery Stores, Hospitals, General Retail Stores``.
*  Luxurious Goods: Includes ``Hotels, Bars, Restaurants``.
*  Transaction metric: Number of transactions is more relevant than the total value.
*  Online and Offline transactions: Both are considered.

Algorithm

#. Add City Column : A new ``city`` column is added based on postal codes (``make_preprocess_location``).
#. Filter for City : Data for the selected city is filtered (``make_filter``).
#. Add Super Category Column : A new ``merch_super_category`` column is added for classifying transactions into luxurious and essential categories (``make_preprocess_location``).
#. Filter by Super Category : Only transactions related to luxurious or essential goods are filtered out (``make_filter``).
#. Filter by Time Frame : Data is filtered for the selected time frame (``make_truncate_time``).
#. Transaction Summing & Noise Addition: Sum the number of transactions by postal code and add Gaussian noise (``make_private_sum_by``).
#. Visualization : Differentially private data is plotted for visualization of pandemic stages.

Sensitivity and Epsilon Analysis

* Sensitivity per Category : Sensitivity is ``3`` for each category (essential or luxurious goods).
* Scaling with Time : For multiple timesteps, sensitivity is ``3 * no_of_time_steps``.
* Epsilon Budget : The epsilon spent per timestep is ∈.
* Scale Calculation : ``Scale = (3 * no_of_time_steps) / ∈``.



Contact Pattern Matrix Estimation
---------------------------------

Description

Estimates the contact matrix by analyzing transactional data for different age groups across various merchandise categories.

Assumptions

#. Proportion of Age Groups : Assumed participation in merchandise categories follows an age group proportion map.

 * References: `research paper <https://www.researchgate.net/figure/Passenger-age-distribution-and-choice-of-airline-model_tbl3_229358687>`_

 * This age group distribution for various merchandise categories can be made more accurate by referring to the data from `<https://www.statista.com/>`_.
 
  .. code-block:: python

     age_group_proportion_map = {
    'Airlines': [25, 40, 15],
    'Bars/Discotheques': [50, 35, 15],
    'Hospitals' : [15, 20, 30],
    'Drug Stores/Pharmacies' : [15, 20, 30 ],
    'Computer Network/Information Services': [40, 35, 20],
    'General Retail Stores': [20, 35, 25],
    'Grocery Stores/Supermarkets': [20, 35, 25],
    'Utilities: Electric, Gas, Water': [15, 30, 30],
    'Hotels/Motels': [20, 25, 30],
    'Restaurants': [25, 25, 25]
    }

#. The persons, involved in the transactions, only make contact with individuals also involved in the transactions from the data.
#. Every transaction under ``nb_transactions`` is done by a unique individual and this is true across different merchant IDs as well. Thus, total number of unique individuals is equal to the total number of transactions across all the merchant IDs.
#. The contacts among various age groups is exclusive ie every individual, from any given age group, make contact with distinct individuals from other age groups.. In the video, they also took this assumptions.

Algorithm

#. Filter Week : Select the specific week for analysis.
#. Filter City : Choose the city of interest (e.g., ``Bogotá``).
#. Filter OFFLINE Transactions : Only consider offline transactions.
#. Group by Merchant Category : Sum the number of transactions (``nb_transactions``).
#. Private Count of Postal Codes: Obtain the private count of unique postal codes for each merchant category and week.
#. Compute Private Mean Transactions : Calculate the average number of transactions per zip code using the age group proportion map.

Sensitivity and Epsilon Analysis

* Sensitivity per Merchant: Sensitivity is 3 for each merchant in the ``Airline`` category.
* Scaling with Time: For multiple timesteps, sensitivity is ``3 * no_of_time_steps``.
* Scaling with Upper Bound: Sensitivity is further scaled by the upper bound of the number of transactions for any merchant category after doing group by with zip code and merchant category. Updated sensitivity is ``3 * no_of_time_steps * upper_bound``.
* Epsilon Budget: The epsilon spent per timestep is ∈ .
* Scale Calculation: ``Scale = (3 * no_of_time_steps * uppper_bound) / ∈``.

Challenges

* Ensuring the contact matrix accurately reflects transaction participation from different age groups.
* Making the contact matrix symmetric to ensure mutual interaction between age groups.
* Difficulty in gathering granular public data for more detailed age group division.




File Strurcture
---------------
* dist
    * dp_epidemiology-0.0.2-py3-none-any.whl
    * dp_epidemiology-0.0.2.tar.gz

* docs
    * api.rst
    * conf.py
    * index.rst
    * make.bat
    * Makefile
    * requirements.in 
    * requirements.txt - This file contains the required libraries for the project.
    * usage.rst - This file contains the usage of the project.

* src
    * DP_epidemiology
        * contact_matrix.py - This module contains the implementation of the contact matrix estimation.
        * hotspot_analyzer.py - This module contains the implementation of the hotspot detection.
        * mobility_analyzer.py - This module contains the implementation of the mobility detection.
        * pandemic_stage_analyzer.py - This module contains the implementation of the pandemic stage detection.
        * utilities.py - This module contains the utility functions used in the other modules.
        * viz.py - This module contains the function for plotly visualization app for hotspot, mobility, pandemic stage detection and contact matrix estimation.
        * ``__init__.py``

* tests
    * test.py - This module contains the test cases for all the modules in the src folder.
