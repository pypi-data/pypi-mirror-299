{"version":3,"file":"postiats-CQpG440k.js","sources":["../../node_modules/monaco-editor/esm/vs/basic-languages/postiats/postiats.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Artyom Shalkhakov. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *\n *  Based on the ATS/Postiats lexer by Hongwei Xi.\n *--------------------------------------------------------------------------------------------*/\nexport var conf = {\n    comments: {\n        lineComment: '//',\n        blockComment: ['(*', '*)']\n    },\n    brackets: [\n        ['{', '}'],\n        ['[', ']'],\n        ['(', ')'],\n        ['<', '>']\n    ],\n    autoClosingPairs: [\n        { open: '\"', close: '\"', notIn: ['string', 'comment'] },\n        { open: '{', close: '}', notIn: ['string', 'comment'] },\n        { open: '[', close: ']', notIn: ['string', 'comment'] },\n        { open: '(', close: ')', notIn: ['string', 'comment'] }\n    ]\n};\nexport var language = {\n    tokenPostfix: '.pats',\n    // TODO: staload and dynload are followed by a special kind of string literals\n    // with {$IDENTIFER} variables, and it also may make sense to highlight\n    // the punctuation (. and / and \\) differently.\n    // Set defaultToken to invalid to see what you do not tokenize yet\n    defaultToken: 'invalid',\n    // keyword reference: https://github.com/githwxi/ATS-Postiats/blob/master/src/pats_lexing_token.dats\n    keywords: [\n        //\n        'abstype',\n        'abst0ype',\n        'absprop',\n        'absview',\n        'absvtype',\n        'absviewtype',\n        'absvt0ype',\n        'absviewt0ype',\n        //\n        'as',\n        //\n        'and',\n        //\n        'assume',\n        //\n        'begin',\n        //\n        /*\n                \"case\", // CASE\n        */\n        //\n        'classdec',\n        //\n        'datasort',\n        //\n        'datatype',\n        'dataprop',\n        'dataview',\n        'datavtype',\n        'dataviewtype',\n        //\n        'do',\n        //\n        'end',\n        //\n        'extern',\n        'extype',\n        'extvar',\n        //\n        'exception',\n        //\n        'fn',\n        'fnx',\n        'fun',\n        //\n        'prfn',\n        'prfun',\n        //\n        'praxi',\n        'castfn',\n        //\n        'if',\n        'then',\n        'else',\n        //\n        'ifcase',\n        //\n        'in',\n        //\n        'infix',\n        'infixl',\n        'infixr',\n        'prefix',\n        'postfix',\n        //\n        'implmnt',\n        'implement',\n        //\n        'primplmnt',\n        'primplement',\n        //\n        'import',\n        //\n        /*\n                \"lam\", // LAM\n                \"llam\", // LLAM\n                \"fix\", // FIX\n        */\n        //\n        'let',\n        //\n        'local',\n        //\n        'macdef',\n        'macrodef',\n        //\n        'nonfix',\n        //\n        'symelim',\n        'symintr',\n        'overload',\n        //\n        'of',\n        'op',\n        //\n        'rec',\n        //\n        'sif',\n        'scase',\n        //\n        'sortdef',\n        /*\n        // HX: [sta] is now deprecated\n        */\n        'sta',\n        'stacst',\n        'stadef',\n        'static',\n        /*\n                \"stavar\", // T_STAVAR\n        */\n        //\n        'staload',\n        'dynload',\n        //\n        'try',\n        //\n        'tkindef',\n        //\n        /*\n                \"type\", // TYPE\n        */\n        'typedef',\n        'propdef',\n        'viewdef',\n        'vtypedef',\n        'viewtypedef',\n        //\n        /*\n                \"val\", // VAL\n        */\n        'prval',\n        //\n        'var',\n        'prvar',\n        //\n        'when',\n        'where',\n        //\n        /*\n                \"for\", // T_FOR\n                \"while\", // T_WHILE\n        */\n        //\n        'with',\n        //\n        'withtype',\n        'withprop',\n        'withview',\n        'withvtype',\n        'withviewtype' // WITHVIEWTYPE\n        //\n    ],\n    keywords_dlr: [\n        '$delay',\n        '$ldelay',\n        //\n        '$arrpsz',\n        '$arrptrsize',\n        //\n        '$d2ctype',\n        //\n        '$effmask',\n        '$effmask_ntm',\n        '$effmask_exn',\n        '$effmask_ref',\n        '$effmask_wrt',\n        '$effmask_all',\n        //\n        '$extern',\n        '$extkind',\n        '$extype',\n        '$extype_struct',\n        //\n        '$extval',\n        '$extfcall',\n        '$extmcall',\n        //\n        '$literal',\n        //\n        '$myfilename',\n        '$mylocation',\n        '$myfunction',\n        //\n        '$lst',\n        '$lst_t',\n        '$lst_vt',\n        '$list',\n        '$list_t',\n        '$list_vt',\n        //\n        '$rec',\n        '$rec_t',\n        '$rec_vt',\n        '$record',\n        '$record_t',\n        '$record_vt',\n        //\n        '$tup',\n        '$tup_t',\n        '$tup_vt',\n        '$tuple',\n        '$tuple_t',\n        '$tuple_vt',\n        //\n        '$break',\n        '$continue',\n        //\n        '$raise',\n        //\n        '$showtype',\n        //\n        '$vcopyenv_v',\n        '$vcopyenv_vt',\n        //\n        '$tempenver',\n        //\n        '$solver_assert',\n        '$solver_verify' // T_DLRSOLVERIFY\n    ],\n    keywords_srp: [\n        //\n        '#if',\n        '#ifdef',\n        '#ifndef',\n        //\n        '#then',\n        //\n        '#elif',\n        '#elifdef',\n        '#elifndef',\n        //\n        '#else',\n        '#endif',\n        //\n        '#error',\n        //\n        '#prerr',\n        '#print',\n        //\n        '#assert',\n        //\n        '#undef',\n        '#define',\n        //\n        '#include',\n        '#require',\n        //\n        '#pragma',\n        '#codegen2',\n        '#codegen3' // T_SRPCODEGEN3 // for level-3 codegen\n        //\n        // HX: end of special tokens\n        //\n    ],\n    irregular_keyword_list: [\n        'val+',\n        'val-',\n        'val',\n        'case+',\n        'case-',\n        'case',\n        'addr@',\n        'addr',\n        'fold@',\n        'free@',\n        'fix@',\n        'fix',\n        'lam@',\n        'lam',\n        'llam@',\n        'llam',\n        'viewt@ype+',\n        'viewt@ype-',\n        'viewt@ype',\n        'viewtype+',\n        'viewtype-',\n        'viewtype',\n        'view+',\n        'view-',\n        'view@',\n        'view',\n        'type+',\n        'type-',\n        'type',\n        'vtype+',\n        'vtype-',\n        'vtype',\n        'vt@ype+',\n        'vt@ype-',\n        'vt@ype',\n        'viewt@ype+',\n        'viewt@ype-',\n        'viewt@ype',\n        'viewtype+',\n        'viewtype-',\n        'viewtype',\n        'prop+',\n        'prop-',\n        'prop',\n        'type+',\n        'type-',\n        'type',\n        't@ype',\n        't@ype+',\n        't@ype-',\n        'abst@ype',\n        'abstype',\n        'absviewt@ype',\n        'absvt@ype',\n        'for*',\n        'for',\n        'while*',\n        'while'\n    ],\n    keywords_types: [\n        'bool',\n        'double',\n        'byte',\n        'int',\n        'short',\n        'char',\n        'void',\n        'unit',\n        'long',\n        'float',\n        'string',\n        'strptr'\n    ],\n    // TODO: reference for this?\n    keywords_effects: [\n        '0',\n        'fun',\n        'clo',\n        'prf',\n        'funclo',\n        'cloptr',\n        'cloref',\n        'ref',\n        'ntm',\n        '1' // all effects\n    ],\n    operators: [\n        '@',\n        '!',\n        '|',\n        '`',\n        ':',\n        '$',\n        '.',\n        '=',\n        '#',\n        '~',\n        //\n        '..',\n        '...',\n        //\n        '=>',\n        // \"=<\", // T_EQLT\n        '=<>',\n        '=/=>',\n        '=>>',\n        '=/=>>',\n        //\n        '<',\n        '>',\n        //\n        '><',\n        //\n        '.<',\n        '>.',\n        //\n        '.<>.',\n        //\n        '->',\n        //\"-<\", // T_MINUSLT\n        '-<>' // T_MINUSLTGT\n        //\n        /*\n                \":<\", // T_COLONLT\n        */\n    ],\n    brackets: [\n        { open: ',(', close: ')', token: 'delimiter.parenthesis' },\n        { open: '`(', close: ')', token: 'delimiter.parenthesis' },\n        { open: '%(', close: ')', token: 'delimiter.parenthesis' },\n        { open: \"'(\", close: ')', token: 'delimiter.parenthesis' },\n        { open: \"'{\", close: '}', token: 'delimiter.parenthesis' },\n        { open: '@(', close: ')', token: 'delimiter.parenthesis' },\n        { open: '@{', close: '}', token: 'delimiter.brace' },\n        { open: '@[', close: ']', token: 'delimiter.square' },\n        { open: '#[', close: ']', token: 'delimiter.square' },\n        { open: '{', close: '}', token: 'delimiter.curly' },\n        { open: '[', close: ']', token: 'delimiter.square' },\n        { open: '(', close: ')', token: 'delimiter.parenthesis' },\n        { open: '<', close: '>', token: 'delimiter.angle' }\n    ],\n    // we include these common regular expressions\n    symbols: /[=><!~?:&|+\\-*\\/\\^%]+/,\n    IDENTFST: /[a-zA-Z_]/,\n    IDENTRST: /[a-zA-Z0-9_'$]/,\n    symbolic: /[%&+-./:=@~`^|*!$#?<>]/,\n    digit: /[0-9]/,\n    digitseq0: /@digit*/,\n    xdigit: /[0-9A-Za-z]/,\n    xdigitseq0: /@xdigit*/,\n    INTSP: /[lLuU]/,\n    FLOATSP: /[fFlL]/,\n    fexponent: /[eE][+-]?[0-9]+/,\n    fexponent_bin: /[pP][+-]?[0-9]+/,\n    deciexp: /\\.[0-9]*@fexponent?/,\n    hexiexp: /\\.[0-9a-zA-Z]*@fexponent_bin?/,\n    irregular_keywords: /val[+-]?|case[+-]?|addr\\@?|fold\\@|free\\@|fix\\@?|lam\\@?|llam\\@?|prop[+-]?|type[+-]?|view[+-@]?|viewt@?ype[+-]?|t@?ype[+-]?|v(iew)?t@?ype[+-]?|abst@?ype|absv(iew)?t@?ype|for\\*?|while\\*?/,\n    ESCHAR: /[ntvbrfa\\\\\\?'\"\\(\\[\\{]/,\n    start: 'root',\n    // The main tokenizer for ATS/Postiats\n    // reference: https://github.com/githwxi/ATS-Postiats/blob/master/src/pats_lexing.dats\n    tokenizer: {\n        root: [\n            // lexing_blankseq0\n            { regex: /[ \\t\\r\\n]+/, action: { token: '' } },\n            // NOTE: (*) is an invalid ML-like comment!\n            { regex: /\\(\\*\\)/, action: { token: 'invalid' } },\n            {\n                regex: /\\(\\*/,\n                action: { token: 'comment', next: 'lexing_COMMENT_block_ml' }\n            },\n            {\n                regex: /\\(/,\n                action: '@brackets' /*{ token: 'delimiter.parenthesis' }*/\n            },\n            {\n                regex: /\\)/,\n                action: '@brackets' /*{ token: 'delimiter.parenthesis' }*/\n            },\n            {\n                regex: /\\[/,\n                action: '@brackets' /*{ token: 'delimiter.bracket' }*/\n            },\n            {\n                regex: /\\]/,\n                action: '@brackets' /*{ token: 'delimiter.bracket' }*/\n            },\n            {\n                regex: /\\{/,\n                action: '@brackets' /*{ token: 'delimiter.brace' }*/\n            },\n            {\n                regex: /\\}/,\n                action: '@brackets' /*{ token: 'delimiter.brace' }*/\n            },\n            // lexing_COMMA\n            {\n                regex: /,\\(/,\n                action: '@brackets' /*{ token: 'delimiter.parenthesis' }*/\n            },\n            { regex: /,/, action: { token: 'delimiter.comma' } },\n            { regex: /;/, action: { token: 'delimiter.semicolon' } },\n            // lexing_AT\n            {\n                regex: /@\\(/,\n                action: '@brackets' /* { token: 'delimiter.parenthesis' }*/\n            },\n            {\n                regex: /@\\[/,\n                action: '@brackets' /* { token: 'delimiter.bracket' }*/\n            },\n            {\n                regex: /@\\{/,\n                action: '@brackets' /*{ token: 'delimiter.brace' }*/\n            },\n            // lexing_COLON\n            {\n                regex: /:</,\n                action: { token: 'keyword', next: '@lexing_EFFECT_commaseq0' }\n            },\n            /*\n            lexing_DOT:\n\n            . // SYMBOLIC => lexing_IDENT_sym\n            . FLOATDOT => lexing_FLOAT_deciexp\n            . DIGIT => T_DOTINT\n            */\n            { regex: /\\.@symbolic+/, action: { token: 'identifier.sym' } },\n            // FLOATDOT case\n            {\n                regex: /\\.@digit*@fexponent@FLOATSP*/,\n                action: { token: 'number.float' }\n            },\n            { regex: /\\.@digit+/, action: { token: 'number.float' } },\n            // lexing_DOLLAR:\n            // '$' IDENTFST IDENTRST* => lexing_IDENT_dlr, _ => lexing_IDENT_sym\n            {\n                regex: /\\$@IDENTFST@IDENTRST*/,\n                action: {\n                    cases: {\n                        '@keywords_dlr': { token: 'keyword.dlr' },\n                        '@default': { token: 'namespace' } // most likely a module qualifier\n                    }\n                }\n            },\n            // lexing_SHARP:\n            // '#' IDENTFST IDENTRST* => lexing_ident_srp, _ => lexing_IDENT_sym\n            {\n                regex: /\\#@IDENTFST@IDENTRST*/,\n                action: {\n                    cases: {\n                        '@keywords_srp': { token: 'keyword.srp' },\n                        '@default': { token: 'identifier' }\n                    }\n                }\n            },\n            // lexing_PERCENT:\n            { regex: /%\\(/, action: { token: 'delimiter.parenthesis' } },\n            {\n                regex: /^%{(#|\\^|\\$)?/,\n                action: {\n                    token: 'keyword',\n                    next: '@lexing_EXTCODE',\n                    nextEmbedded: 'text/javascript'\n                }\n            },\n            { regex: /^%}/, action: { token: 'keyword' } },\n            // lexing_QUOTE\n            { regex: /'\\(/, action: { token: 'delimiter.parenthesis' } },\n            { regex: /'\\[/, action: { token: 'delimiter.bracket' } },\n            { regex: /'\\{/, action: { token: 'delimiter.brace' } },\n            [/(')(\\\\@ESCHAR|\\\\[xX]@xdigit+|\\\\@digit+)(')/, ['string', 'string.escape', 'string']],\n            [/'[^\\\\']'/, 'string'],\n            // lexing_DQUOTE\n            [/\"/, 'string.quote', '@lexing_DQUOTE'],\n            // lexing_BQUOTE\n            {\n                regex: /`\\(/,\n                action: '@brackets' /* { token: 'delimiter.parenthesis' }*/\n            },\n            // TODO: otherwise, try lexing_IDENT_sym\n            { regex: /\\\\/, action: { token: 'punctuation' } },\n            // lexing_IDENT_alp:\n            // NOTE: (?!regex) is syntax for \"not-followed-by\" regex\n            // to resolve ambiguity such as foreach$fwork being incorrectly lexed as [for] [each$fwork]!\n            {\n                regex: /@irregular_keywords(?!@IDENTRST)/,\n                action: { token: 'keyword' }\n            },\n            {\n                regex: /@IDENTFST@IDENTRST*[<!\\[]?/,\n                action: {\n                    cases: {\n                        // TODO: dynload and staload should be specially parsed\n                        // dynload whitespace+ \"special_string\"\n                        // this special string is really:\n                        //  '/' '\\\\' '.' => punctuation\n                        // ({\\$)([a-zA-Z_][a-zA-Z_0-9]*)(}) => punctuation,keyword,punctuation\n                        // [^\"] => identifier/literal\n                        '@keywords': { token: 'keyword' },\n                        '@keywords_types': { token: 'type' },\n                        '@default': { token: 'identifier' }\n                    }\n                }\n            },\n            // lexing_IDENT_sym:\n            {\n                regex: /\\/\\/\\/\\//,\n                action: { token: 'comment', next: '@lexing_COMMENT_rest' }\n            },\n            { regex: /\\/\\/.*$/, action: { token: 'comment' } },\n            {\n                regex: /\\/\\*/,\n                action: { token: 'comment', next: '@lexing_COMMENT_block_c' }\n            },\n            // AS-20160627: specifically for effect annotations\n            {\n                regex: /-<|=</,\n                action: { token: 'keyword', next: '@lexing_EFFECT_commaseq0' }\n            },\n            {\n                regex: /@symbolic+/,\n                action: {\n                    cases: {\n                        '@operators': 'keyword',\n                        '@default': 'operator'\n                    }\n                }\n            },\n            // lexing_ZERO:\n            // FIXME: this one is quite messy/unfinished yet\n            // TODO: lexing_INT_hex\n            // - testing_hexiexp => lexing_FLOAT_hexiexp\n            // - testing_fexponent_bin => lexing_FLOAT_hexiexp\n            // - testing_intspseq0 => T_INT_hex\n            // lexing_INT_hex:\n            {\n                regex: /0[xX]@xdigit+(@hexiexp|@fexponent_bin)@FLOATSP*/,\n                action: { token: 'number.float' }\n            },\n            { regex: /0[xX]@xdigit+@INTSP*/, action: { token: 'number.hex' } },\n            {\n                regex: /0[0-7]+(?![0-9])@INTSP*/,\n                action: { token: 'number.octal' }\n            },\n            //{regex: /0/, action: { token: 'number' } }, // INTZERO\n            // lexing_INT_dec:\n            // - testing_deciexp => lexing_FLOAT_deciexp\n            // - testing_fexponent => lexing_FLOAT_deciexp\n            // - otherwise => intspseq0 ([0-9]*[lLuU]?)\n            {\n                regex: /@digit+(@fexponent|@deciexp)@FLOATSP*/,\n                action: { token: 'number.float' }\n            },\n            {\n                regex: /@digit@digitseq0@INTSP*/,\n                action: { token: 'number.decimal' }\n            },\n            // DIGIT, if followed by digitseq0, is lexing_INT_dec\n            { regex: /@digit+@INTSP*/, action: { token: 'number' } }\n        ],\n        lexing_COMMENT_block_ml: [\n            [/[^\\(\\*]+/, 'comment'],\n            [/\\(\\*/, 'comment', '@push'],\n            [/\\(\\*/, 'comment.invalid'],\n            [/\\*\\)/, 'comment', '@pop'],\n            [/\\*/, 'comment']\n        ],\n        lexing_COMMENT_block_c: [\n            [/[^\\/*]+/, 'comment'],\n            // [/\\/\\*/, 'comment', '@push' ],    // nested C-style block comments not allowed\n            // [/\\/\\*/,    'comment.invalid' ],\t// NOTE: this breaks block comments in the shape of /* //*/\n            [/\\*\\//, 'comment', '@pop'],\n            [/[\\/*]/, 'comment']\n        ],\n        lexing_COMMENT_rest: [\n            [/$/, 'comment', '@pop'],\n            [/.*/, 'comment']\n        ],\n        // NOTE: added by AS, specifically for highlighting\n        lexing_EFFECT_commaseq0: [\n            {\n                regex: /@IDENTFST@IDENTRST+|@digit+/,\n                action: {\n                    cases: {\n                        '@keywords_effects': { token: 'type.effect' },\n                        '@default': { token: 'identifier' }\n                    }\n                }\n            },\n            { regex: /,/, action: { token: 'punctuation' } },\n            { regex: />/, action: { token: '@rematch', next: '@pop' } }\n        ],\n        lexing_EXTCODE: [\n            {\n                regex: /^%}/,\n                action: {\n                    token: '@rematch',\n                    next: '@pop',\n                    nextEmbedded: '@pop'\n                }\n            },\n            { regex: /[^%]+/, action: '' }\n        ],\n        lexing_DQUOTE: [\n            { regex: /\"/, action: { token: 'string.quote', next: '@pop' } },\n            // AS-20160628: additional hi-lighting for variables in staload/dynload strings\n            {\n                regex: /(\\{\\$)(@IDENTFST@IDENTRST*)(\\})/,\n                action: [\n                    { token: 'string.escape' },\n                    { token: 'identifier' },\n                    { token: 'string.escape' }\n                ]\n            },\n            { regex: /\\\\$/, action: { token: 'string.escape' } },\n            {\n                regex: /\\\\(@ESCHAR|[xX]@xdigit+|@digit+)/,\n                action: { token: 'string.escape' }\n            },\n            { regex: /[^\\\\\"]+/, action: { token: 'string' } }\n        ]\n    }\n};\n"],"names":["conf","language"],"mappings":"AAMU,IAACA,EAAO,CACd,SAAU,CACN,YAAa,KACb,aAAc,CAAC,KAAM,IAAI,CAC5B,EACD,SAAU,CACN,CAAC,IAAK,GAAG,EACT,CAAC,IAAK,GAAG,EACT,CAAC,IAAK,GAAG,EACT,CAAC,IAAK,GAAG,CACZ,EACD,iBAAkB,CACd,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,CAAC,SAAU,SAAS,CAAG,EACvD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,CAAC,SAAU,SAAS,CAAG,EACvD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,CAAC,SAAU,SAAS,CAAG,EACvD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,CAAC,SAAU,SAAS,CAAG,CAC1D,CACL,EACWC,EAAW,CAClB,aAAc,QAKd,aAAc,UAEd,SAAU,CAEN,UACA,WACA,UACA,UACA,WACA,cACA,YACA,eAEA,KAEA,MAEA,SAEA,QAMA,WAEA,WAEA,WACA,WACA,WACA,YACA,eAEA,KAEA,MAEA,SACA,SACA,SAEA,YAEA,KACA,MACA,MAEA,OACA,QAEA,QACA,SAEA,KACA,OACA,OAEA,SAEA,KAEA,QACA,SACA,SACA,SACA,UAEA,UACA,YAEA,YACA,cAEA,SAQA,MAEA,QAEA,SACA,WAEA,SAEA,UACA,UACA,WAEA,KACA,KAEA,MAEA,MACA,QAEA,UAIA,MACA,SACA,SACA,SAKA,UACA,UAEA,MAEA,UAKA,UACA,UACA,UACA,WACA,cAKA,QAEA,MACA,QAEA,OACA,QAOA,OAEA,WACA,WACA,WACA,YACA,cAEH,EACD,aAAc,CACV,SACA,UAEA,UACA,cAEA,WAEA,WACA,eACA,eACA,eACA,eACA,eAEA,UACA,WACA,UACA,iBAEA,UACA,YACA,YAEA,WAEA,cACA,cACA,cAEA,OACA,SACA,UACA,QACA,UACA,WAEA,OACA,SACA,UACA,UACA,YACA,aAEA,OACA,SACA,UACA,SACA,WACA,YAEA,SACA,YAEA,SAEA,YAEA,cACA,eAEA,aAEA,iBACA,gBACH,EACD,aAAc,CAEV,MACA,SACA,UAEA,QAEA,QACA,WACA,YAEA,QACA,SAEA,SAEA,SACA,SAEA,UAEA,SACA,UAEA,WACA,WAEA,UACA,YACA,WAIH,EACD,uBAAwB,CACpB,OACA,OACA,MACA,QACA,QACA,OACA,QACA,OACA,QACA,QACA,OACA,MACA,OACA,MACA,QACA,OACA,aACA,aACA,YACA,YACA,YACA,WACA,QACA,QACA,QACA,OACA,QACA,QACA,OACA,SACA,SACA,QACA,UACA,UACA,SACA,aACA,aACA,YACA,YACA,YACA,WACA,QACA,QACA,OACA,QACA,QACA,OACA,QACA,SACA,SACA,WACA,UACA,eACA,YACA,OACA,MACA,SACA,OACH,EACD,eAAgB,CACZ,OACA,SACA,OACA,MACA,QACA,OACA,OACA,OACA,OACA,QACA,SACA,QACH,EAED,iBAAkB,CACd,IACA,MACA,MACA,MACA,SACA,SACA,SACA,MACA,MACA,GACH,EACD,UAAW,CACP,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IAEA,KACA,MAEA,KAEA,MACA,OACA,MACA,QAEA,IACA,IAEA,KAEA,KACA,KAEA,OAEA,KAEA,KAKH,EACD,SAAU,CACN,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,uBAAyB,EAC1D,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,iBAAmB,EACpD,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,kBAAoB,EACrD,CAAE,KAAM,KAAM,MAAO,IAAK,MAAO,kBAAoB,EACrD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,iBAAmB,EACnD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,kBAAoB,EACpD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,uBAAyB,EACzD,CAAE,KAAM,IAAK,MAAO,IAAK,MAAO,iBAAmB,CACtD,EAED,QAAS,wBACT,SAAU,YACV,SAAU,iBACV,SAAU,yBACV,MAAO,QACP,UAAW,UACX,OAAQ,cACR,WAAY,WACZ,MAAO,SACP,QAAS,SACT,UAAW,kBACX,cAAe,kBACf,QAAS,sBACT,QAAS,gCACT,mBAAoB,0LACpB,OAAQ,wBACR,MAAO,OAGP,UAAW,CACP,KAAM,CAEF,CAAE,MAAO,aAAc,OAAQ,CAAE,MAAO,EAAE,CAAI,EAE9C,CAAE,MAAO,SAAU,OAAQ,CAAE,MAAO,SAAS,CAAI,EACjD,CACI,MAAO,OACP,OAAQ,CAAE,MAAO,UAAW,KAAM,yBAA2B,CAChE,EACD,CACI,MAAO,KACP,OAAQ,WACX,EACD,CACI,MAAO,KACP,OAAQ,WACX,EACD,CACI,MAAO,KACP,OAAQ,WACX,EACD,CACI,MAAO,KACP,OAAQ,WACX,EACD,CACI,MAAO,KACP,OAAQ,WACX,EACD,CACI,MAAO,KACP,OAAQ,WACX,EAED,CACI,MAAO,MACP,OAAQ,WACX,EACD,CAAE,MAAO,IAAK,OAAQ,CAAE,MAAO,iBAAiB,CAAI,EACpD,CAAE,MAAO,IAAK,OAAQ,CAAE,MAAO,qBAAqB,CAAI,EAExD,CACI,MAAO,MACP,OAAQ,WACX,EACD,CACI,MAAO,MACP,OAAQ,WACX,EACD,CACI,MAAO,MACP,OAAQ,WACX,EAED,CACI,MAAO,KACP,OAAQ,CAAE,MAAO,UAAW,KAAM,0BAA4B,CACjE,EAQD,CAAE,MAAO,eAAgB,OAAQ,CAAE,MAAO,gBAAgB,CAAI,EAE9D,CACI,MAAO,+BACP,OAAQ,CAAE,MAAO,cAAgB,CACpC,EACD,CAAE,MAAO,YAAa,OAAQ,CAAE,MAAO,cAAc,CAAI,EAGzD,CACI,MAAO,wBACP,OAAQ,CACJ,MAAO,CACH,gBAAiB,CAAE,MAAO,aAAe,EACzC,WAAY,CAAE,MAAO,WAAa,CACrC,CACJ,CACJ,EAGD,CACI,MAAO,wBACP,OAAQ,CACJ,MAAO,CACH,gBAAiB,CAAE,MAAO,aAAe,EACzC,WAAY,CAAE,MAAO,YAAc,CACtC,CACJ,CACJ,EAED,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,uBAAuB,CAAI,EAC5D,CACI,MAAO,gBACP,OAAQ,CACJ,MAAO,UACP,KAAM,kBACN,aAAc,iBACjB,CACJ,EACD,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,SAAS,CAAI,EAE9C,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,uBAAuB,CAAI,EAC5D,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,mBAAmB,CAAI,EACxD,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,iBAAiB,CAAI,EACtD,CAAC,6CAA8C,CAAC,SAAU,gBAAiB,QAAQ,CAAC,EACpF,CAAC,WAAY,QAAQ,EAErB,CAAC,IAAK,eAAgB,gBAAgB,EAEtC,CACI,MAAO,MACP,OAAQ,WACX,EAED,CAAE,MAAO,KAAM,OAAQ,CAAE,MAAO,aAAa,CAAI,EAIjD,CACI,MAAO,mCACP,OAAQ,CAAE,MAAO,SAAW,CAC/B,EACD,CACI,MAAO,6BACP,OAAQ,CACJ,MAAO,CAOH,YAAa,CAAE,MAAO,SAAW,EACjC,kBAAmB,CAAE,MAAO,MAAQ,EACpC,WAAY,CAAE,MAAO,YAAc,CACtC,CACJ,CACJ,EAED,CACI,MAAO,WACP,OAAQ,CAAE,MAAO,UAAW,KAAM,sBAAwB,CAC7D,EACD,CAAE,MAAO,UAAW,OAAQ,CAAE,MAAO,SAAS,CAAI,EAClD,CACI,MAAO,OACP,OAAQ,CAAE,MAAO,UAAW,KAAM,yBAA2B,CAChE,EAED,CACI,MAAO,QACP,OAAQ,CAAE,MAAO,UAAW,KAAM,0BAA4B,CACjE,EACD,CACI,MAAO,aACP,OAAQ,CACJ,MAAO,CACH,aAAc,UACd,WAAY,UACf,CACJ,CACJ,EAQD,CACI,MAAO,kDACP,OAAQ,CAAE,MAAO,cAAgB,CACpC,EACD,CAAE,MAAO,uBAAwB,OAAQ,CAAE,MAAO,YAAY,CAAI,EAClE,CACI,MAAO,0BACP,OAAQ,CAAE,MAAO,cAAgB,CACpC,EAMD,CACI,MAAO,wCACP,OAAQ,CAAE,MAAO,cAAgB,CACpC,EACD,CACI,MAAO,0BACP,OAAQ,CAAE,MAAO,gBAAkB,CACtC,EAED,CAAE,MAAO,iBAAkB,OAAQ,CAAE,MAAO,QAAQ,CAAI,CAC3D,EACD,wBAAyB,CACrB,CAAC,WAAY,SAAS,EACtB,CAAC,OAAQ,UAAW,OAAO,EAC3B,CAAC,OAAQ,iBAAiB,EAC1B,CAAC,OAAQ,UAAW,MAAM,EAC1B,CAAC,KAAM,SAAS,CACnB,EACD,uBAAwB,CACpB,CAAC,UAAW,SAAS,EAGrB,CAAC,OAAQ,UAAW,MAAM,EAC1B,CAAC,QAAS,SAAS,CACtB,EACD,oBAAqB,CACjB,CAAC,IAAK,UAAW,MAAM,EACvB,CAAC,KAAM,SAAS,CACnB,EAED,wBAAyB,CACrB,CACI,MAAO,8BACP,OAAQ,CACJ,MAAO,CACH,oBAAqB,CAAE,MAAO,aAAe,EAC7C,WAAY,CAAE,MAAO,YAAc,CACtC,CACJ,CACJ,EACD,CAAE,MAAO,IAAK,OAAQ,CAAE,MAAO,aAAa,CAAI,EAChD,CAAE,MAAO,IAAK,OAAQ,CAAE,MAAO,WAAY,KAAM,OAAU,CAC9D,EACD,eAAgB,CACZ,CACI,MAAO,MACP,OAAQ,CACJ,MAAO,WACP,KAAM,OACN,aAAc,MACjB,CACJ,EACD,CAAE,MAAO,QAAS,OAAQ,EAAI,CACjC,EACD,cAAe,CACX,CAAE,MAAO,IAAK,OAAQ,CAAE,MAAO,eAAgB,KAAM,OAAU,EAE/D,CACI,MAAO,kCACP,OAAQ,CACJ,CAAE,MAAO,eAAiB,EAC1B,CAAE,MAAO,YAAc,EACvB,CAAE,MAAO,eAAiB,CAC7B,CACJ,EACD,CAAE,MAAO,MAAO,OAAQ,CAAE,MAAO,eAAe,CAAI,EACpD,CACI,MAAO,mCACP,OAAQ,CAAE,MAAO,eAAiB,CACrC,EACD,CAAE,MAAO,UAAW,OAAQ,CAAE,MAAO,QAAQ,CAAI,CACpD,CACJ,CACL","x_google_ignoreList":[0]}